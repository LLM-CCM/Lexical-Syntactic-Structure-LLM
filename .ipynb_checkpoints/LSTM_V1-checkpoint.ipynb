{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e90851d-fa34-45bc-8df7-0599353547f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a022b4f-32bc-4560-9005-2fa5eabf4f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Read the contents of the text file\n",
    "with open(\"data/Elman.txt\", \"r\") as file:\n",
    "    text = file.read()\n",
    "    \n",
    "def remove_non_ascii(s):\n",
    "    return re.sub(r'[^\\x00-\\x7F]+|\\d', '', s)\n",
    "\n",
    "# Create a PorterStemmer object\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Splitting the text into sentences\n",
    "sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s|\\n', text)\n",
    "sentences = [remove_non_ascii(item) for item in sentences]\n",
    "# print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "283c5920-1360-48bf-b42f-57fb30126b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "def preprocess(sentence):\n",
    "    # Convert to lowercase\n",
    "    sentence = sentence.lower()\n",
    "    # Remove punctuation\n",
    "    sentence = sentence.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    # Tokenize the sentence\n",
    "    words = sentence.split()\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    return stemmed_words\n",
    "    # return words\n",
    "\n",
    "# Applying the preprocessing function to each sentence\n",
    "preprocessed_sentences = [preprocess(sentence) for sentence in sentences]\n",
    "sentences_tokens = [['<SOS>']+s+['<EOS>'] for s in preprocessed_sentences]\n",
    "# print(sentences_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "726b822d-52df-4d5d-9327-9214425a9b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping unique tokens to integers: {'<EOS>': 0, '<SOS>': 1, 'book': 2, 'boy': 3, 'bread': 4, 'break': 5, 'car': 6, 'cat': 7, 'chase': 8, 'cooki': 9, 'dog': 10, 'dragon': 11, 'eat': 12, 'exist': 13, 'girl': 14, 'glass': 15, 'like': 16, 'lion': 17, 'man': 18, 'monster': 19, 'mous': 20, 'move': 21, 'plate': 22, 'rock': 23, 'sandwich': 24, 'see': 25, 'sleep': 26, 'smash': 27, 'smell': 28, 'think': 29, 'woman': 30} \n",
      "\n",
      "example sentence as string: <SOS> dragon break plate <EOS> \n",
      "\n",
      "example sentence as tensor: tensor([ 1, 11,  5, 22,  0]) \n",
      "\n",
      "['<EOS>', '<SOS>', 'book', 'boy', 'bread', 'break', 'car', 'cat', 'chase', 'cooki', 'dog', 'dragon', 'eat', 'exist', 'girl', 'glass', 'like', 'lion', 'man', 'monster', 'mous', 'move', 'plate', 'rock', 'sandwich', 'see', 'sleep', 'smash', 'smell', 'think', 'woman']\n"
     ]
    }
   ],
   "source": [
    "unique_tokens = sorted(set(sum(sentences_tokens,[])))\n",
    "# print(unique_tokens)\n",
    "def sentenceToTensor(tokens_list):\n",
    "    # Convert list of strings to tensor of token indices (integers)\n",
    "    #\n",
    "    # Input\n",
    "    #  tokens_list : list of strings, e.g. ['<SOS>','lion','eat','man','<EOS>']\n",
    "    # Output\n",
    "    #  1D tensor of the same length (integers), e.g., tensor([ 2, 18, 13, 19,  0])\n",
    "    assert(isinstance(tokens_list,list))\n",
    "    tokens_index = [token_to_index[token] for token in tokens_list]\n",
    "    return torch.tensor(tokens_index)\n",
    "\n",
    "n_tokens = len(unique_tokens) # all words and special tokens\n",
    "token_to_index = {t : i for i,t in enumerate(unique_tokens)}\n",
    "index_to_token = {i : t for i,t in enumerate(unique_tokens)}\n",
    "training_pats = [sentenceToTensor(s) for s in sentences_tokens] # python list of 1D sentence tensors\n",
    "ntrain = len(training_pats)\n",
    "print('mapping unique tokens to integers: %s \\n' % token_to_index)\n",
    "print('example sentence as string: %s \\n' % ' '.join(sentences_tokens[0]))\n",
    "print('example sentence as tensor: %s \\n' % training_pats[0])\n",
    "\n",
    "print(unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30755248-7687-491e-b564-cd92b4695dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "         # Embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "        # Fully connected layer (output layer)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state and cell state\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        \n",
    "        # LSTM forward pass\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Extract the output of the last time step and pass it through the fully connected layer\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def initHidden(self):\n",
    "        # Returns length hidden_size 1D tensor of zeros\n",
    "        return torch.zeros(self.hidden_size)\n",
    "    \n",
    "    def get_embeddings(self):\n",
    "        # Returns [vocab_size x hidden_size] numpy array of input embeddings\n",
    "        return self.embed(torch.arange(self.vocab_size)).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b4861e5-fd78-4657-a610-fc177cbff0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(seq_tensor, lstm):\n",
    "    # Process a sentence and update the SRN weights. With <SOS> as the input at step 0,\n",
    "    # predict every subsequent word given the past words.\n",
    "    # Return the mean loss across each symbol prediction.\n",
    "    #\n",
    "    # Input\n",
    "    #   seq_tensor: [1D tensor] sentence as token indices\n",
    "    #   rnn : instance of SRN class\n",
    "    # Output\n",
    "    #   loss : [scalar] average NLL loss across prediction steps\n",
    "    # TODO : YOUR CODE GOES HERE\n",
    "    \n",
    "    hidden = lstm.initHidden()\n",
    "    lstm.train()\n",
    "    lstm.zero_grad()\n",
    "    loss = 0\n",
    "    seq_length = seq_tensor.shape[0]\n",
    "\n",
    "    for i in range(seq_length - 1):\n",
    "        output, hidden = lstm(seq_tensor[i])\n",
    "        loss += criterion(output, seq_tensor[i+1]) \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item() / float(seq_length-1)\n",
    "    # raise Exception('Replace with your code.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74c47cc6-9b9a-48c6-9fd0-21f882752fc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension specified as 0 but tensor has no dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/k8/6g72kjgs713cjq6n0w8jlst80000gn/T/ipykernel_43876/571990664.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0merror_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_pats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0merror_epoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0merror_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_epoch\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_pats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/k8/6g72kjgs713cjq6n0w8jlst80000gn/T/ipykernel_43876/568748066.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(seq_tensor, lstm)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_length\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/k8/6g72kjgs713cjq6n0w8jlst80000gn/T/ipykernel_43876/3204918382.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Initialize hidden state and cell state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mh0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mc0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension specified as 0 but tensor has no dimensions"
     ]
    }
   ],
   "source": [
    "input_size = 10  # The number of features in your input\n",
    "hidden_size = 128  # The number of hidden units in the LSTM layer\n",
    "num_layers = 2  # The number of stacked LSTM layers\n",
    "output_size = 1  # The size of the output (e.g., for a regression problem, it's 1)\n",
    "nepochs = 20\n",
    "\n",
    "lstm = LSTMModel(input_size, hidden_size, num_layers, output_size)\n",
    "optimizer = torch.optim.AdamW(lstm.parameters(), weight_decay=0.04) # w/ default learning rate 0.001\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "for i in range(nepochs):\n",
    "    perm = np.random.permutation(len(training_pats))\n",
    "    error_epoch = 0.\n",
    "    for p in perm:\n",
    "        loss = train(training_pats[p], lstm)\n",
    "        error_epoch += loss\n",
    "    error_epoch = error_epoch / float(len(training_pats)) \n",
    "    print(f\"loss for epoch {i+1} is: {error_epoch}\")\n",
    "# raise Exception('Replace with your code.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2b4da2-aacd-4391-9663-3a6bf50c659d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
